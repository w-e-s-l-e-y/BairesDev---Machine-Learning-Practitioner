{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN4NTDaNajhOFrOtcH3K2nf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/w-e-s-l-e-y/BairesDev---Machine-Learning-Practitioner/blob/main/Exercicio_detec%C3%A7%C3%A3o_rede_yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yc9EVP-mEXfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eeb8396-23d5-48a5-815b-1ca9496397a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-397-gde62f93c Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 34.0/112.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Clonar o repositÃ³rio YOLOv5\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "\n",
        "# Instalar dependÃªncias\n",
        "!pip install -qr requirements.txt\n",
        "\n",
        "# Importar bibliotecas e inicializar configuraÃ§Ãµes\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Executar detecÃ§Ã£o em imagens de exemplo\n",
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images\n",
        "\n",
        "# Mostrar uma das imagens detectadas (opcional)\n",
        "# display.Image(filename='runs/detect/exp/zidane.jpg', width=600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UueJJfV7JuHR",
        "outputId": "32b9c347-e52c-441d-c74c-325580b08568"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_format=0, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-397-gde62f93c Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "image 1/2 /content/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 29.9ms\n",
            "image 2/2 /content/yolov5/data/images/zidane.jpg: 384x640 2 persons, 2 ties, 29.6ms\n",
            "Speed: 0.5ms pre-process, 29.7ms inference, 62.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar e descompactar o conjunto de dados COCO128\n",
        "torch.hub.download_url_to_file('https://github.com/ultralytics/assets/releases/download/v0.0.0/coco128.zip', 'coco128.zip')\n",
        "!unzip -oq coco128.zip -d ../datasets && rm coco128.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CybC8IHqJxiG",
        "outputId": "5813609c-c9c1-4821-d8ea-8ba4adbd478e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.66M/6.66M [00:00<00:00, 267MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinamento do YOLOv5s no conjunto de dados COCO128\n",
        "\n",
        "# OpÃ§Ã£o: TensorBoard (descomente as linhas abaixo se quiser usar o TensorBoard)\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir runs/train\n",
        "\n",
        "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsntNTuuJ06u",
        "outputId": "455c60bb-b2b7-4aa2-9da3-98a3bb500355"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-30 12:25:38.167269: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1738239938.203038   11929 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1738239938.213913   11929 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v7.0-397-gde62f93c Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "COMET WARNING: Comet credentials have not been set. Comet will default to offline logging. Please set your credentials to enable online logging.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Using '/content/yolov5/.cometml-runs' path as offline directory. Pass 'offline_directory' parameter into constructor or set the 'COMET_OFFLINE_DIRECTORY' environment variable to manually choose where to store offline experiment archives.\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n",
            "\n",
            "Transferred 349/349 items from yolov5s.pt\n",
            "/content/yolov5/models/common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "/content/yolov5/models/common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:00<00:00, 418.62it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:00<00:00, 128.95it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp2/labels.jpg... \n",
            "/content/yolov5/train.py:355: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp2\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/8 [00:00<?, ?it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        0/2      3.72G    0.04758    0.05486    0.01542        211        640:  12% 1/8 [00:03<00:27,  3.90s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        0/2      3.76G    0.04567    0.06548    0.01513        242        640:  25% 2/8 [00:04<00:11,  1.85s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        0/2      3.76G    0.04559    0.06507    0.01713        234        640:  38% 3/8 [00:04<00:06,  1.23s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        0/2      3.76G     0.0451    0.06248     0.0179        182        640:  50% 4/8 [00:05<00:03,  1.01it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        0/2      3.76G    0.04499     0.0601    0.01852        158        640:  62% 5/8 [00:06<00:02,  1.15it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        0/2      3.76G    0.04553    0.06121    0.01792        215        640:  75% 6/8 [00:06<00:01,  1.30it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        0/2      3.76G    0.04581     0.0644    0.01782        292        640:  88% 7/8 [00:07<00:00,  1.53it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        0/2      3.76G     0.0453    0.06487    0.01818        194        640: 100% 8/8 [00:07<00:00,  1.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:10<00:00,  2.66s/it]\n",
            "                   all        128        929      0.679      0.605      0.684      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/8 [00:00<?, ?it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        1/2      4.61G    0.04551    0.06297    0.01211        196        640:  12% 1/8 [00:00<00:02,  2.87it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        1/2      4.61G    0.04264    0.07199    0.01399        245        640:  25% 2/8 [00:00<00:02,  2.55it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        1/2      4.61G    0.04407    0.07896    0.01574        286        640:  38% 3/8 [00:01<00:01,  2.61it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        1/2      4.61G    0.04424    0.07652    0.01582        233        640:  50% 4/8 [00:01<00:01,  2.54it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        1/2      4.61G     0.0448    0.07581    0.01692        249        640:  62% 5/8 [00:01<00:01,  2.54it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        1/2      4.61G    0.04429    0.07325     0.0168        195        640:  75% 6/8 [00:02<00:00,  2.62it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        1/2      4.61G    0.04436    0.07376    0.01688        267        640:  88% 7/8 [00:02<00:00,  2.75it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        1/2      4.61G    0.04367    0.07197    0.01642        199        640: 100% 8/8 [00:03<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.17s/it]\n",
            "                   all        128        929      0.716      0.626       0.71      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/8 [00:00<?, ?it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        2/2      4.61G     0.0459     0.0626    0.01276        237        640:  12% 1/8 [00:00<00:01,  4.06it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        2/2      4.61G     0.0449    0.05678    0.01539        185        640:  25% 2/8 [00:00<00:01,  4.23it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        2/2      4.61G    0.04412    0.05497    0.01565        162        640:  38% 3/8 [00:00<00:01,  3.73it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        2/2      4.61G    0.04534      0.062    0.01668        303        640:  50% 4/8 [00:01<00:01,  3.98it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        2/2      4.61G     0.0454    0.06505    0.01655        226        640:  62% 5/8 [00:01<00:00,  3.95it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        2/2      4.61G    0.04545    0.06713    0.01625        251        640:  75% 6/8 [00:01<00:00,  4.11it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        2/2      4.61G    0.04535    0.06653     0.0164        184        640:  88% 7/8 [00:01<00:00,  3.59it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "        2/2      4.61G    0.04511    0.06581    0.01651        193        640: 100% 8/8 [00:02<00:00,  3.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.19it/s]\n",
            "                   all        128        929      0.727      0.636      0.726      0.486\n",
            "\n",
            "3 epochs completed in 0.009 hours.\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 14.8MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 14.8MB\n",
            "\n",
            "Validating runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.02it/s]\n",
            "                   all        128        929      0.727      0.636      0.727      0.487\n",
            "                person        128        254      0.867       0.72      0.808      0.526\n",
            "               bicycle        128          6      0.564      0.333      0.592      0.345\n",
            "                   car        128         46       0.82      0.397      0.553      0.237\n",
            "            motorcycle        128          5      0.689          1      0.862      0.586\n",
            "              airplane        128          6      0.972          1      0.995      0.688\n",
            "                   bus        128          7      0.569      0.714      0.781      0.672\n",
            "                 train        128          3          1       0.57      0.913      0.611\n",
            "                 truck        128         12      0.647      0.333      0.462      0.252\n",
            "                  boat        128          6      0.722      0.333      0.467      0.224\n",
            "         traffic light        128         14      0.612      0.227      0.365      0.197\n",
            "             stop sign        128          2      0.811          1      0.995      0.796\n",
            "                 bench        128          9       0.69      0.499      0.665      0.296\n",
            "                  bird        128         16      0.961          1      0.995      0.648\n",
            "                   cat        128          4      0.887          1      0.995      0.797\n",
            "                   dog        128          9      0.968      0.667      0.869      0.621\n",
            "                 horse        128          2      0.834          1      0.995      0.622\n",
            "              elephant        128         17      0.972      0.882      0.934      0.728\n",
            "                  bear        128          1      0.683          1      0.995      0.995\n",
            "                 zebra        128          4      0.856          1      0.995       0.96\n",
            "               giraffe        128          9      0.784      0.809      0.902      0.667\n",
            "              backpack        128          6      0.867        0.5      0.753      0.339\n",
            "              umbrella        128         18       0.86      0.778      0.884      0.507\n",
            "               handbag        128         19      0.697      0.263      0.335      0.184\n",
            "                   tie        128          7      0.767      0.714      0.787       0.49\n",
            "              suitcase        128          4      0.655          1      0.945      0.606\n",
            "               frisbee        128          5      0.718        0.8      0.759       0.66\n",
            "                  skis        128          1          0          0     0.0585     0.0138\n",
            "             snowboard        128          7      0.819      0.654      0.829      0.528\n",
            "           sports ball        128          6      0.598      0.667      0.602      0.327\n",
            "                  kite        128         10       0.74        0.6      0.611      0.235\n",
            "          baseball bat        128          4      0.635        0.5      0.535        0.2\n",
            "        baseball glove        128          7      0.482      0.429      0.469      0.299\n",
            "            skateboard        128          5          1       0.59      0.707      0.455\n",
            "         tennis racket        128          7      0.609      0.429      0.504      0.303\n",
            "                bottle        128         18      0.578      0.381      0.553      0.267\n",
            "            wine glass        128         16      0.734      0.875      0.874      0.475\n",
            "                   cup        128         36      0.842      0.738      0.815      0.519\n",
            "                  fork        128          6          1      0.315      0.456      0.303\n",
            "                 knife        128         16      0.766      0.615       0.71      0.438\n",
            "                 spoon        128         22      0.718      0.455      0.624      0.361\n",
            "                  bowl        128         28      0.753      0.607      0.722      0.548\n",
            "                banana        128          1      0.913          1      0.995      0.301\n",
            "              sandwich        128          2          1          0      0.606      0.535\n",
            "                orange        128          4       0.69          1      0.995       0.66\n",
            "              broccoli        128         11      0.414      0.455      0.437      0.333\n",
            "                carrot        128         24      0.618      0.667      0.737      0.499\n",
            "               hot dog        128          2      0.395          1      0.995      0.846\n",
            "                 pizza        128          5      0.827          1      0.962      0.714\n",
            "                 donut        128         14      0.634          1      0.944      0.806\n",
            "                  cake        128          4      0.866          1      0.995      0.822\n",
            "                 chair        128         35      0.595      0.629      0.607      0.321\n",
            "                 couch        128          6      0.871      0.667      0.855      0.549\n",
            "          potted plant        128         14      0.713      0.786      0.835      0.495\n",
            "                   bed        128          3      0.401      0.267      0.746      0.399\n",
            "          dining table        128         13      0.824      0.363      0.585      0.335\n",
            "                toilet        128          2      0.789          1      0.995      0.846\n",
            "                    tv        128          2      0.589          1      0.995      0.846\n",
            "                laptop        128          3          1          0      0.602      0.301\n",
            "                 mouse        128          2          1          0          0          0\n",
            "                remote        128          8          1      0.618      0.629      0.538\n",
            "            cell phone        128          8      0.378       0.25      0.344      0.186\n",
            "             microwave        128          3      0.755          1      0.995      0.778\n",
            "                  oven        128          5       0.36        0.4      0.434      0.265\n",
            "                  sink        128          6      0.465      0.333      0.351      0.245\n",
            "          refrigerator        128          5      0.563        0.8      0.799      0.533\n",
            "                  book        128         29      0.518      0.207       0.35      0.179\n",
            "                 clock        128          9      0.768      0.889      0.916      0.721\n",
            "                  vase        128          2      0.319          1      0.995      0.821\n",
            "              scissors        128          1          1          0      0.497     0.0498\n",
            "            teddy bear        128         21      0.818      0.642      0.791      0.522\n",
            "            toothbrush        128          5      0.803      0.817      0.928      0.577\n",
            "Results saved to \u001b[1mruns/train/exp2\u001b[0m\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml OfflineExperiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : exp\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : [OfflineExperiment will get URL after upload]\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [3]                 : (1.8858516216278076, 2.5456433296203613)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP_0.5 [6]      : (0.6835440624486755, 0.726034634470304)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP_0.5:0.95 [6] : (0.457556602492091, 0.4864841979807111)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision [6]    : (0.6791493683461854, 0.7265791610031552)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall [6]       : (0.605375524096936, 0.635877762037897)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (0.043669551610946655, 0.04529991000890732)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (0.016418561339378357, 0.018179820850491524)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/obj_loss [6]       : (0.06486806273460388, 0.07196730375289917)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (0.0399678535759449, 0.041134096682071686)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (0.00881195068359375, 0.010472774505615234)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/obj_loss [6]         : (0.037041664123535156, 0.03827667236328125)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     x/lr0 [6]                : (0.077782, 0.0937)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     x/lr1 [6]                : (0.0007, 0.001005)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     x/lr2 [6]                : (0.0007, 0.001005)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name                        : exp\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_log_batch_metrics     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_log_confusion_matrix  : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_log_per_class_metrics : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_max_image_uploads     : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_mode                  : online\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_model_name            : yolov5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hasNestedParams             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     offline_experiment          : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     anchor_t            : 4.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     artifact_alias      : latest\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size          : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bbox_interval       : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box                 : 0.05\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bucket              : \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg                 : \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls                 : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls_pw              : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr              : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device              : \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     entity              : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     evolve              : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     evolve_population   : data/hyps\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fl_gamma            : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr              : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud              : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze              : [0]\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h               : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s               : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v               : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|anchor_t        : 4.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|box             : 0.05\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|cls_pw          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|fl_gamma        : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|iou_t           : 0.2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|obj             : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|obj_pw          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     image_weights       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz               : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou_t               : 0.2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     local_rank          : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0                 : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf                 : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup               : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum            : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic              : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                : exp\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     ndjson_console      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     ndjson_file         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     noautoanchor        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     noplots             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nosave              : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     noval               : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     obj                 : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     obj_pw              : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer           : SGD\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience            : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project             : runs/train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     quad                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume              : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume_evolve       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir            : runs/train/exp2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period         : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale               : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed                : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear               : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     sync_bn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate           : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     upload_dataset      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_conf_threshold  : 0.001\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_iou_threshold   : 0.6\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr      : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs       : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum     : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay        : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers             : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset               : 13 (3.97 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata        : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 106\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still saving offline stats to messages file before program termination (may take up to 120 seconds)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Begin archiving the offline data.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m To upload this offline experiment, run:\n",
            "    comet upload /content/yolov5/.cometml-runs/ae83395e20da4ef1a9ef410e26bdc750.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# InferÃªncia com o modelo YOLOv5 do PyTorch Hub\n",
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)\n",
        "im = 'https://ultralytics.com/images/zidane.jpg'\n",
        "results = model(im)\n",
        "results.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59rSD1uvJ3Ef",
        "outputId": "09393639-5b86-494d-be22-cc9caa3c76d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 ðŸš€ v7.0-397-gde62f93c Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n",
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "image 1/1: 720x1280 2 persons, 1 tie, 1 cell phone\n",
            "Speed: 2568.3ms pre-process, 44.9ms inference, 160.6ms NMS per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    }
  ]
}